# dpo_implementation
Implementation of Direct Preference Optimization
